\section{Описание}

\par В данном курсовом проекте, на языке с++ была реализована задача "Аудио поиска". То есть требовалось составить базу на основе некоторой выборки аудиофайлов, а затем производить среди них поиск файла, который больше остальных совпадает с образцом. Для того, чтобы выполнить эту задачу, необходимо изучить базовые понятия теории звука. 

Звук -- это вибрации, которые распространяются в твёрдых, жидких и газообразных средах и могут расшифровываться ушами. Эти вибрации могут быть смоделированы с помощью синусоидальной формы.\\

\noindent \textbf{Чистые тона и реальные звуки}

Чистый тон -- это звук, который можно представить в виде синусоиды.
Синусоидальный сигнал характеризуется частотой -- количество тактов в секунду (измеряется в Герцах) и амплитудой -- размер каждого такта. Человек может слышать чистые тона от 20 Гц до 20 000 Гц и этот диапазон уменьшается с возрастом. Восприятие громкости зависит от частоты чистого тона. Например, чистый тон с амплитудой 10 и частотой 30 Гц будет тише, чем чистый тон с амплитудой 10 и частотой 1000 Гц.

Но чистые тона не существуют в обычной природе, каждый звук в мире - это сумма нескольких чистых тонов при различных амплитудах. Реальный звук может состоять из тысячи чистых тонов.\\

\noindent \textbf{Спектограмма}

В песня обычно присутствует несколько инструментов, а иногда и несколько певцов. Все эти инструменты создают комбинацию синусоид кратных частот и в целом представляет собой еще большее сочетание синусоид.

Музыку возможно наглядно представить на спектрограмме. Обычно это диаграмма с тремя измерениями, где на горизонтальной оси у нас есть время, на вертикальной оси - частота чистого тона, и третье измерение описывается цветом и представляет собой амплитуду частот в определенное время.\\

\noindent \textbf{Sampling}

Аналоговые сигналы - это непрерывные сигналы, что означает, что если взять одну секунду аналогового сигнала, то можно разделить эту секунду на сколько угодно частей. В цифровом мире мы не можем позволить себе хранить бесконечное количество информации. Мы должны иметь минимальную единицу, например, 1 миллисекунда. В течение этой единицы времени звук не может меняться, так что этот блок должен быть достаточно коротким, чтобы цифровая песня звучала как аналоговая, но в тоже время и достаточно большим, чтобы ограничить пространство, необходимое для хранения музыки. 

Стандартная единица времени в цифровой музыке составляет 44 100 единиц в секунду. Именно это число используется потому, что по теореме Найквиста-Шеннона, для того, чтобы сигнал был восстановлен однозначно и без потерь, необходимо использовать частоту в 2 раза больше максимальной, а человек способен слышать звуки от 20гц до 20кГц. Это значит, что нужно использовать частоту не менее 40000Гц, но в 80-х годах музыкальные корпорации (например, Sony) выбрали 44100 Гц, так как это было больше 40000 Гц и совместимо со стандартами видео NTSC и PAL.\\

\noindent \textbf{Квантование}

Мы узнали, как оцифровать частоты музыки, но что делать с громкостью? Громкость является относительной мерой. Для одинаковой громкости в сигнале, если увеличить громкость колонок звук будет выше. Громкость измеряет разброс между самым низким и самым высоким уровнем звука в песне. 

Квантование - это разбиение диапазона значений непрерывной или дискретной величины на конечное число интервалов. В музыке стандартно уровень квантования кодируется на 16 бит, что означает 65536 уровней.\\

\noindent \textbf{От цифрового звука к частотам}

Мы знаем, как перейти от аналогового звука в цифровой. Но как получить частоты из цифрового сигнала? Эта важно, так как аудио поиск работает только с частотами. Для аналоговых (и, следовательно, непрерывных) сигналов, происходит преобразование, называемое "непрерывные преобразование Фурье"(НПФ). Это преобразование превращает функцию времени в функцию частоты. Для дискретного же сигнала существует "дискретное преобразование Фурье"(ДПФ).

Примечание: ДПФ применимо только для одного канала, поэтому, если мы имеем стереосигнал, нам нужно превратить его в моно.\\

\noindent \textbf{Дискретное преобразование Фурье}

ДПФ применяется для дискретных сигналов и дает дискретный спектр (частоты в сигнале). Вот формула для преобразования цифрового сигнала в частоту

\begin{center}
	{\Large $X(n) = \sum^{N-1}\limits_{k=0} x[k]e^{-j(2\pi kn/N)}$}
\end{center}

В этой формуле: 
\begin{itemize}
	\item N -- это размер окна: количество образцов, из которых состоит сигнал.
	\item Х(n) -- n-й "контейнер"\, частот.
	\item х(k) -- k-й семпл звукового сигнала.
\end{itemize}

Здесь используется "контейнер"\, частот, а не частота, потому что ДПФ дает дискретный спектр и "контейнер"\, частот является наименьшей единицей частоты, которую ДПФ может вычислить. Размер "контейнера"\, называется частотным разрешением и равен частоте дискретизации сигнала, деленной на размер окна.\\

\noindent \textbf{Оконные функции}

Если мы хотим получить частоту каждых 0.1 секундных частей в односекундной музыке, то надо применить преобразование Фурье сначала к первой 0.1 секундной части, потом ко второй и тд. Это делается с помощью применения к сигналу оконной функции. Но эта функция также производит спектральные утечки -- появление новых частот, ранее не существовавших внутри звукового сигнала. Получаются они из-за того, что сильные частоты влияют на более слабые соседние.

Мы не можем полностью избежать спектральных утечек, но мы можем контролировать, как утечка будет себя вести при правильном выборе оконной функции. Существуют такие оконные функции, как: прямоугольное окно, окно Блэкмана, окно Хемминга и др.

Прямоугольное окно, самое простое в использовании, так как нужно просто разделить сигнал на маленькие части. Оно хорошо применимо для синусоид сопоставимой силы, но это плохой выбор для синусоид различных амплитуд (что и имеет место в песне).

Окно Блэкмана лучше, для того, чтобы избежать случая, когда утечка спектра сильных частот скрывает слабые частоты. Но, оно плохо работает с шумом, и скрывает даже больше частот чем прямоугольное окно. Это проблема для аудио поиска, так как в поисковых образцах могут содержаться посторонние шумы.

Окно Хэмминга находится между этими двумя крайностями и является лучшим выбором для алгоритма аудио поиска.\\

\noindent \textbf{Быстрое преобразование Фурье}

В дискретном преобразование Фурье для вычисления одного "контейнера"\, нам потребуется N сложений и N умножений (где N это размер окна), что дает сложность $O(n^2)$, что очень много. Но к счастью существует реализация ДПФ, которая работает за $O(nlogn)$ и называется быстрое преобразование Фурье(БПФ). Это важное ускорение, так как никто не хочет долго ждать, чтобы найти песню.\\

Самая простая реализация БПФ - это алгоритм, который работает по принципу разделяй и властвуй. Идея заключается в том, что вместо прямого вычисления преобразования Фурье на N-образец окна, алгоритм:

\begin{itemize}
	\item делит окно-образец на 2 N/2-образца окна.
	\item вычисляет (рекурсивно) БПФ для 2 N/2-образцов окна.
	\item эффективно вычисляет БПФ для N-окон из 2-х предыдущих БПФ.
\end{itemize}

\noindent \textbf{Downsampling}

Можно заметить, что увеличение размера окна улучшает частотное разрешение, но оно также увеличивает время вычислений. Но есть трюк, который помогает сохранить частотное разрешение и уменьшить размер окна в то же время, это называется downsampling. Если взять, например, песню с 44100Гц, и понизить частоту до 11025Гц (44100/4), то мы получим то же частотное разрешение, применив БПФ к 44100Гц песне с 4096 окном или применив БПФ к 11025Гц песне с 1024 окном. Единственное различие заключается в том, что измененной песне, будут только частоты от 0 до 5000Гц. На самом деле большинство не слышат большой разницы между музыкой в 11025Гц и музыкой в 44100Гц. 

Понижение сделать очень просто, достаточно взять группу, например, из 4 семплов и превратить их в один, взяв среднее значение. Единственный нюанс состоит в том, что перед понижением сигнала нужно отфильтровать высокие частоты в звуке, чтобы избежать наложения спектров.

В итоге все основные частоты сохраняются в песне, и при этом улучшается скорость работы алгоритма.\\

\noindent \textbf{Реализация}

При реализации программы мы используем библиотеку для работы с аудио -- mpg123. При ее инициализации задаем частоту равной 41000Гц, использование одного канала и кодировку float. Это было проделывается для того, чтобы все песни считывались в одинаковом формате.

Построчно читая названия песен из файла, мы открываем их и, считывая данные по частям, фильтруем высокие частоты и делаем понижение частоты, беря среднее значение от каждых четырех семплов.

Только после этого мы запускаем быстрое преобразование Фурье. Один из неприятных побочных эффектов БПФ заключается в том, что, проведя анализ, мы теряем информацию о времени.  Мы можем видеть звуковые частоты и их амплитуды, но вот где именно в произведении эти частоты встречаются, не знаем. Нам нужно как-то узнать точные значения времени, когда появляется каждая из частот. Именно поэтому мы будем пользоваться чем-то вроде скользящего окна, и подвергать трансформации лишь ту часть сигнала, которая в это окно попадает.

Как только у нас будут сведения о частотных характеристиках сигнала, можно приступать к формированию цифровой сигнатуры музыкального произведения. Это – самая важная часть всего процесса распознавания музыки. Главная сложность здесь – выбрать из огромного количества частот именно те, которые важнее всего. Обычно мы обращаем внимание на частоты с максимальными амплитудами. Однако, в одной песне диапазон сильных частот может варьироваться очень сильно. Поэтому, вместо того, чтобы сразу проанализировать весь частотный диапазон, мы можем выбрать несколько более мелких интервалов и найти в них частоты с самыми высокими уровнями. Эти сведения и формируют сигнатуру для конкретного анализируемого блока данных, а она, в свою очередь, является частью сигнатуры всей песни.

Для упрощения поиска музыкальных композиций их сигнатуры используются как ключи в хэш-таблице. Ключам соответствуют значения времени, когда набор частот, для которых найдена сигнатура, появился в произведении, и идентификатор самого произведения (название песни). 

После обработки таким способом всю библиотеку музыкальных записей, мы получаем базу данных с полными сигнатурами каждого произведения.

Для того, чтобы распознать песню, еще нужно прогнать через вышеописанный процесс вычисления сигнатур. Затем запустить поиск вычисленных хэш-тегов в базе данных.

Но у многих фрагментов различных произведений хэш-тэги совпадают. Всякий раз, когда удаётся обнаружить совпадающий хэш-тег, число возможных совпадений уменьшается, но весьма вероятно, что только лишь эти сведения не позволят нам настолько сузить диапазон поиска, чтобы остановиться на единственной правильной песне. Поэтому в алгоритме распознавания музыкальных произведений нам нужно проверять ещё отметки времени.

Фрагмент песни, который мы ищем, может быть из любого её места, поэтому мы просто не в состоянии напрямую сравнивать относительное время внутри записанного фрагмента с тем, что есть в базе данных. 

Однако если найдено несколько совпадений, можно проанализировать относительный тайминг совпадений, и, таким образом, повысить достоверность поиска.

И маловероятно, что каждый обработанный фрагмент песни полностью совпадёт с аналогичным фрагментом из базы данных. Поэтому, вместо того, чтобы исключать из списка совпадений всё, кроме единственной верной композиции, в конце поиска мы вычисляем процент совпавших семплов и та песня, у которой процент наибольший и будет является ответом. Если же процент совпадения меньше 10\%, то песня считается ненайденной.

\pagebreak
